app = "ollama-desculpa-ai"
primary_region = "gru"

[build]
dockerfile = "./ollama/Dockerfile.app"

[mounts]
source = "ollama_data"
destination = "/root/.ollama"

[env]
OLLAMA_HOST = "0.0.0.0:11434"

[[services]]
internal_port = 11434
protocol = "tcp"
processes = ["app"]

[[services.ports]]
handlers = []

[checks]
[checks.ollama]
port = 11434
type = "tcp"
interval = "15s"
timeout = "2s"

[deploy]
strategy = "rolling"

[experimental]
auto_rollback = true

[processes]
app = ""

[scale]
min = 1
max = 4

[[vm]]
memory = "4gb"
cpu_kind = "shared"
cpus = 4
